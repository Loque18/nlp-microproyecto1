{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéºü§ñ ArmonIA - generaci√≥n de musica con redes neuronales\n",
    "\n",
    "## Introducci√≥n\n",
    "\n",
    "armonIA es un proyecto que busca generar m√∫sica utilizando redes neuronales. El objetivo es crear un modelo capaz de componer m√∫sica original en diferentes estilos de musica clasica, utilizando t√©cnicas de aprendizaje profundo y procesamiento de lenguaje natural. En este proyecto, se utilizar√° Torch para construir y entrenar el modelo.\n",
    "\n",
    "\n",
    "### Prologo\n",
    "\n",
    "Antes de comenzar con el desarrollo del proyecto, es importante entender los datos que se tienen y lo que cada uno representa, a continuaci√≥n se lista cada uno de los datos de entrada \n",
    "\n",
    "Caracter√≠sticas de entrada \n",
    "\n",
    "| Caracter√≠stica | Tipo de Variable | Descripci√≥n                                                                |\n",
    "|----------------|------------------|----------------------------------------------------------------------------|\n",
    "| Pitch          | Categ√≥rica       | Representa la altura de la nota musical (`note.pitch`).                    |\n",
    "| Step           | Num√©rica         | Diferencia entre el `start` de la nota actual y el `start` de la anterior. |\n",
    "| Duration       | Num√©rica         | Diferencia entre el `end` y el `start` de la nota actual.                  |\n",
    "| Velocity       | Num√©rica         | Representa la velocidad de la nota (`note.velocity`).                      |\n",
    "\n",
    "\n",
    "Como las variables Step y Duration son num√©ricas, se normalizan para que est√©n en el rango [0, 1]. La variable Velocity se normaliza para que est√© en el rango [0, 127]. La variable Pitch se convierte a una representaci√≥n num√©rica utilizando un diccionario de mapeo.\n",
    "\n",
    "\n",
    "en este caso no es necesario eliminar los datos duplicados, ya que cada nota es √∫nica y no se repite en el tiempo. Sin embargo, es importante asegurarse de qe no haya datos nulos o vac√≠os en el conjunto de datos.\n",
    "\n",
    "Se realiza un dise√±o primero de la arquitectura del modelo, para luego proceder a la implementaci√≥n del mismo. El modelo se basa en una red neuronal LSTM (Long Short-Term Memory) que es capaz de aprender patrones en secuencias de datos. La arquitectura del modelo se puede ver en la siguiente imagen: \n",
    "\n",
    "<div style=\"display: flex; gap: 32px; justify-content: center; item-align: center; width: 100%;\">\n",
    "    <!-- <img style=\"width:400px\" src=\"https://www.researchgate.net/publication/385782855/figure/fig1/AS:11431281290276122@1731539282950/LSTM-model-architecture-for-song-generation-Adapted-from-9.ppm\" /> -->\n",
    "    <img src=\"./lstm.png\" style=\"width:500px\" alt=\"LSTM model architecture for song generation\" />\n",
    "    <div>\n",
    "        Se utilizar√° un modelo LSTM para la generaci√≥n de m√∫sica debido a su capacidad para manejar secuencias de datos. El modelo tomar√° como entrada una secuencia de notas y acordes, y generar√° una nueva secuencia de notas y acordes como salida.\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "## Fases del proyecto\n",
    "\n",
    "### 1. Pre procesamiento de datos\n",
    "\n",
    "Para entrenar un modelo de generaci√≥n de m√∫sica, es necesario contar con un conjunto de datos que contenga ejemplos de m√∫sica en el estilo deseado. En este caso, se utilizar√° un conjunto de datos de partituras musicales en formato MIDI. Se utilizar√°n bibliotecas como `pretty-midi` para procesar y analizar los archivos MIDI.\n",
    "\n",
    "En esta etapa se realizar√°n las siguientes tareas:\n",
    "\n",
    "1. Cargar los archivos MIDI y extraer las notas y acordes.\n",
    "2. Convertir las notas y acordes en una representaci√≥n num√©rica que pueda ser utilizada por el modelo.\n",
    "3. Dividir los datos en secuencias de longitud fija para facilitar el entrenamiento del modelo.\n",
    "4. Normalizar los datos para mejorar la convergencia del modelo.\n",
    "5. Dividir los datos en conjuntos de entrenamiento y validaci√≥n.\n",
    "\n",
    "\n",
    "\n",
    "### 2. Construcci√≥n, entrenamiento y evaluaci√≥n del modelo\n",
    "\n",
    "\n",
    "Para la construcci√≥n del modelo se utilizar√° la biblioteca `torch` para crear una red neuronal LSTM. El modelo tomar√° como entrada una secuencia de notas y acordes, y generar√° una nueva secuencia de notas y acordes como salida. Se utilizar√°n capas LSTM para capturar las dependencias temporales en los datos, y se aplicar√°n t√©cnicas de regularizaci√≥n como Dropout para evitar el sobreajuste.\n",
    "\n",
    "Lista de pasos a seguir:\n",
    "\n",
    "1. Definir la arquitectura del modelo LSTM.\n",
    "2. Definir la funci√≥n de p√©rdida y el optimizador.\n",
    "3. Implementar el bucle de entrenamiento y validaci√≥n.\n",
    "4. Guardar el modelo entrenado para su uso posterior.\n",
    "5. Evaluar el modelo utilizando m√©tricas como la p√©rdida y la precisi√≥n.\n",
    "\n",
    "\n",
    "### 3. Generaci√≥n de m√∫sica\n",
    "\n",
    "Para generar m√∫sica, se utilizar√° el modelo entrenado para predecir la siguiente nota o acorde dado una secuencia de notas y acordes inicial. Se implementar√° un algoritmo de muestreo para generar nuevas secuencias de notas y acordes, y se utilizar√°n t√©cnicas de post-procesamiento para convertir las secuencias generadas en archivos MIDI.\n",
    "\n",
    "Lista de pasos a seguir:\n",
    "\n",
    "1. Cargar el modelo entrenado.\n",
    "2. Definir una secuencia inicial de notas y acordes.\n",
    "3. Utilizar el modelo para predecir la siguiente nota o acorde.\n",
    "4. Repetir el proceso para generar una secuencia completa de notas y acordes.\n",
    "5. Convertir la secuencia generada en un archivo MIDI.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Pre procesamiento de datos\n",
    "\n",
    "### 1.1 Impotar librerias necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "\n",
    "from typing import List, Tuple, Dict, Any, Union \n",
    "\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pretty_midi\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 Crear funciones para cargar y procesar los archivos MIDI\n",
    "\n",
    "se crean las funciones necesarias para cargar y procesar los archivos MIDI. Se utiliza la biblioteca `pretty_midi` para cargar los archivos MIDI y extraer las notas y acordes. Se definen funciones para convertir las notas y acordes en una representaci√≥n num√©rica, dividir los datos en secuencias de longitud fija, normalizar los datos y dividir los datos en conjuntos de entrenamiento y validaci√≥n.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicDataset(Dataset):\n",
    "    def __init__(self, X: List[np.ndarray], y: List[int], seq_length: int = 32, label_encoder: LabelEncoder):\n",
    "\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.label_encoder = \n",
    "\n",
    "        self.data = data\n",
    "        self.seq_length = seq_length\n",
    "        self.scaler = MinMaxScaler()\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self._prepare_data()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def _prepare_data(self):\n",
    "        # Extract features and labels\n",
    "        features, labels = zip(*self.data)\n",
    "        \n",
    "        # Scale features\n",
    "        features = np.array(features)\n",
    "        self.scaler.fit(features.reshape(-1, features.shape[-1]))\n",
    "        features = self.scaler.transform(features.reshape(-1, features.shape[-1])).reshape(features.shape)\n",
    "        \n",
    "        # Encode labels\n",
    "        labels = np.array(labels)\n",
    "        self.label_encoder.fit(labels)\n",
    "        labels = self.label_encoder.transform(labels)\n",
    "        \n",
    "        # Split into sequences\n",
    "        self.features = []\n",
    "        self.labels = []\n",
    "        \n",
    "        for i in range(len(features)):\n",
    "            for j in range(0, len(features[i]) - self.seq_length + 1):\n",
    "                self.features.append(features[i][j:j + self.seq_length])\n",
    "                self.labels.append(labels[i])\n",
    "        \n",
    "        self.features = np.array(self.features)\n",
    "        self.labels = np.array(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessor:\n",
    "    \"\"\"permite cargar y preprocesar los archivos midi.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.scaler = MinMaxScaler()\n",
    "        self.label_encoder = LabelEncoder()\n",
    "\n",
    "\n",
    "    # *~~~ api start ~~~*\n",
    "    def load_midi_files(self, filepath: str, target_program = None) -> List[pretty_midi.Note]:\n",
    "        \"\"\"\n",
    "        Carga los archivos MIDI y extrae notas del instrumento especificado.\n",
    "        \"\"\"\n",
    "        try: \n",
    "            midi_data = pretty_midi.PrettyMIDI(filepath)\n",
    "            # Extraer notas de un instrumento espec√≠fico (ej. piano)\n",
    "\n",
    "            if target_program is not None:\n",
    "                instruments = [inst for inst in midi_data.instruments if inst.program == target_program]\n",
    "                if not instruments:\n",
    "                    return []\n",
    "                \n",
    "                instrument = instruments[0]\n",
    "            else:\n",
    "                instrument = midi_data.instruments[0]\n",
    "\n",
    "            # print(f\"list of instruments: {midi_data.instruments}\")\n",
    "\n",
    "            notes = instrument.notes\n",
    "            return notes\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error al cargar archivo midi {e}\")\n",
    "            return None\n",
    "\n",
    "    def extract_features(self, notes: pretty_midi.PrettyMIDI) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Extrae caracter√≠sticas de cada nota: pitch, step, duration (y opcionalmente velocity).\n",
    "        \"\"\"\n",
    "\n",
    "        # se ordenan las notas por tiempo de inicio para\n",
    "        # garantizar que las notas tengan el mismo orden de la melod√≠a\n",
    "        notes = sorted(notes, key=lambda x: x.start) # x[1] es start\n",
    "    \n",
    "        data = []\n",
    "        for i in range(1, len(notes)):\n",
    "            note = notes[i]\n",
    "            prev_note = notes[i-1]\n",
    "            pitch = note.pitch\n",
    "            pitch_name = pretty_midi.note_number_to_name(pitch)\n",
    "            step = note.start - prev_note.start\n",
    "            duration = note.end - note.start\n",
    "            velocity = note.velocity\n",
    "            data.append([pitch_name, step, duration, velocity])\n",
    "\n",
    "        return np.array(data, dtype=object)\n",
    "\n",
    "    def get_notes_dataframe(self, data: np.ndarray) -> pd.DataFrame:\n",
    "        columns = [\"pitch\", \"step\", \"duration\", \"velocity\"]\n",
    "        df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "        # Convertir pitch a string expl√≠citamente (por si NumPy lo convirti√≥)\n",
    "        df[\"pitch\"] = df[\"pitch\"].astype(str)\n",
    "\n",
    "        return df\n",
    "\n",
    "   \n",
    "    def build_sequences(self, data: np.ndarray, context_size: int) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Construye pares (X, Y) para entrenamiento, a partir del array de notas completo.\n",
    "    \n",
    "        - `X`: secuencia de `context_size` notas [nota_t‚àíc, ..., nota_t‚àí1]\n",
    "        - `Y`: nota objetivo nota_t\n",
    "        \"\"\"\n",
    "        X, y = [], []\n",
    "\n",
    "        for i in range(context_size, len(data)):\n",
    "            context = data[i-context_size: i+1]\n",
    "\n",
    "\n",
    "            X.append(context[:-1])  # Todas las notas menos la √∫ltima\n",
    "            y.append(context[-1])  # Solo la √∫ltima nota\n",
    "\n",
    "        X = np.array(X, dtype=object)\n",
    "        y = np.array(y, dtype=object)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def normalize_features(self, X: np.ndarray, y: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Aplica normalizaci√≥n \n",
    "\n",
    "        \"\"\"\n",
    "            \n",
    "        # Convertimos los arrays a float para evitar errores\n",
    "        X = X.copy()\n",
    "        y = y.copy()\n",
    "\n",
    "\n",
    "    def plot_data(self):\n",
    "        \"\"\"Graficar los datos.\"\"\"\n",
    "        pass\n",
    "\n",
    "    # *~~~ api end ~~~*\n",
    "\n",
    "    # *~~~ internal fn start ~~~*\n",
    "    # *~~~ internal fn end ~~~*\n",
    "    \n",
    "\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Buffer has wrong number of dimensions (expected 1, got 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     29\u001b[39m         data.extend(song_sequence.tolist())\n\u001b[32m     31\u001b[39m     all_sequence = preprocessor.build_sequences(data, context_size=\u001b[32m10\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m     df = \u001b[43mpreprocessor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_notes_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_sequence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# df = preprocessor.get_notes_dataframe(data)\u001b[39;00m\n\u001b[32m     38\u001b[39m \n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# print(df)\u001b[39;00m\n\u001b[32m     40\u001b[39m \n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# print(preprocessor.get_notes_dataframe(all_features[0]))\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 39\u001b[39m, in \u001b[36mPreprocessor.get_notes_dataframe\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_notes_dataframe\u001b[39m(\u001b[38;5;28mself\u001b[39m, data: np.ndarray) -> pd.DataFrame:\n\u001b[32m     38\u001b[39m     columns = [\u001b[33m\"\u001b[39m\u001b[33mpitch\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstep\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mduration\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mvelocity\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# Convertir pitch a string expl√≠citamente (por si NumPy lo convirti√≥)\u001b[39;00m\n\u001b[32m     42\u001b[39m     df[\u001b[33m\"\u001b[39m\u001b[33mpitch\u001b[39m\u001b[33m\"\u001b[39m] = df[\u001b[33m\"\u001b[39m\u001b[33mpitch\u001b[39m\u001b[33m\"\u001b[39m].astype(\u001b[38;5;28mstr\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/notebooks/venv/lib/python3.11/site-packages/pandas/core/frame.py:867\u001b[39m, in \u001b[36mDataFrame.__init__\u001b[39m\u001b[34m(self, data, index, columns, dtype, copy)\u001b[39m\n\u001b[32m    859\u001b[39m         mgr = arrays_to_mgr(\n\u001b[32m    860\u001b[39m             arrays,\n\u001b[32m    861\u001b[39m             columns,\n\u001b[32m   (...)\u001b[39m\u001b[32m    864\u001b[39m             typ=manager,\n\u001b[32m    865\u001b[39m         )\n\u001b[32m    866\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m867\u001b[39m         mgr = \u001b[43mndarray_to_mgr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    868\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    869\u001b[39m \u001b[43m            \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    870\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    871\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    873\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    876\u001b[39m     mgr = dict_to_mgr(\n\u001b[32m    877\u001b[39m         {},\n\u001b[32m    878\u001b[39m         index,\n\u001b[32m   (...)\u001b[39m\u001b[32m    881\u001b[39m         typ=manager,\n\u001b[32m    882\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/notebooks/venv/lib/python3.11/site-packages/pandas/core/internals/construction.py:319\u001b[39m, in \u001b[36mndarray_to_mgr\u001b[39m\u001b[34m(values, index, columns, dtype, copy, typ)\u001b[39m\n\u001b[32m    314\u001b[39m     values = _ensure_2d(values)\n\u001b[32m    316\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    317\u001b[39m     \u001b[38;5;66;03m# by definition an array here\u001b[39;00m\n\u001b[32m    318\u001b[39m     \u001b[38;5;66;03m# the dtypes will be coerced to a single dtype\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m     values = \u001b[43m_prep_ndarraylike\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy_on_sanitize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    321\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m values.dtype != dtype:\n\u001b[32m    322\u001b[39m     \u001b[38;5;66;03m# GH#40110 see similar check inside sanitize_array\u001b[39;00m\n\u001b[32m    323\u001b[39m     values = sanitize_array(\n\u001b[32m    324\u001b[39m         values,\n\u001b[32m    325\u001b[39m         \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    328\u001b[39m         allow_2d=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    329\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/notebooks/venv/lib/python3.11/site-packages/pandas/core/internals/construction.py:575\u001b[39m, in \u001b[36m_prep_ndarraylike\u001b[39m\u001b[34m(values, copy)\u001b[39m\n\u001b[32m    569\u001b[39m \u001b[38;5;66;03m# we could have a 1-dim or 2-dim list here\u001b[39;00m\n\u001b[32m    570\u001b[39m \u001b[38;5;66;03m# this is equiv of np.asarray, but does object conversion\u001b[39;00m\n\u001b[32m    571\u001b[39m \u001b[38;5;66;03m# and platform dtype preservation\u001b[39;00m\n\u001b[32m    572\u001b[39m \u001b[38;5;66;03m# does not convert e.g. [1, \"a\", True] to [\"1\", \"a\", \"True\"] like\u001b[39;00m\n\u001b[32m    573\u001b[39m \u001b[38;5;66;03m#  np.asarray would\u001b[39;00m\n\u001b[32m    574\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(values[\u001b[32m0\u001b[39m]):\n\u001b[32m--> \u001b[39m\u001b[32m575\u001b[39m     values = np.array(\u001b[43m[\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[32m    576\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values[\u001b[32m0\u001b[39m], np.ndarray) \u001b[38;5;129;01mand\u001b[39;00m values[\u001b[32m0\u001b[39m].ndim == \u001b[32m0\u001b[39m:\n\u001b[32m    577\u001b[39m     \u001b[38;5;66;03m# GH#21861 see test_constructor_list_of_lists\u001b[39;00m\n\u001b[32m    578\u001b[39m     values = np.array([convert(v) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m values])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/notebooks/venv/lib/python3.11/site-packages/pandas/core/internals/construction.py:575\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    569\u001b[39m \u001b[38;5;66;03m# we could have a 1-dim or 2-dim list here\u001b[39;00m\n\u001b[32m    570\u001b[39m \u001b[38;5;66;03m# this is equiv of np.asarray, but does object conversion\u001b[39;00m\n\u001b[32m    571\u001b[39m \u001b[38;5;66;03m# and platform dtype preservation\u001b[39;00m\n\u001b[32m    572\u001b[39m \u001b[38;5;66;03m# does not convert e.g. [1, \"a\", True] to [\"1\", \"a\", \"True\"] like\u001b[39;00m\n\u001b[32m    573\u001b[39m \u001b[38;5;66;03m#  np.asarray would\u001b[39;00m\n\u001b[32m    574\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(values[\u001b[32m0\u001b[39m]):\n\u001b[32m--> \u001b[39m\u001b[32m575\u001b[39m     values = np.array([\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m values])\n\u001b[32m    576\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values[\u001b[32m0\u001b[39m], np.ndarray) \u001b[38;5;129;01mand\u001b[39;00m values[\u001b[32m0\u001b[39m].ndim == \u001b[32m0\u001b[39m:\n\u001b[32m    577\u001b[39m     \u001b[38;5;66;03m# GH#21861 see test_constructor_list_of_lists\u001b[39;00m\n\u001b[32m    578\u001b[39m     values = np.array([convert(v) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m values])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/notebooks/venv/lib/python3.11/site-packages/pandas/core/internals/construction.py:564\u001b[39m, in \u001b[36m_prep_ndarraylike.<locals>.convert\u001b[39m\u001b[34m(v)\u001b[39m\n\u001b[32m    561\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m v\n\u001b[32m    563\u001b[39m v = extract_array(v, extract_numpy=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m564\u001b[39m res = \u001b[43mmaybe_convert_platform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    565\u001b[39m \u001b[38;5;66;03m# We don't do maybe_infer_to_datetimelike here bc we will end up doing\u001b[39;00m\n\u001b[32m    566\u001b[39m \u001b[38;5;66;03m#  it column-by-column in ndarray_to_mgr\u001b[39;00m\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/notebooks/venv/lib/python3.11/site-packages/pandas/core/dtypes/cast.py:138\u001b[39m, in \u001b[36mmaybe_convert_platform\u001b[39m\u001b[34m(values)\u001b[39m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m arr.dtype == _dtype_obj:\n\u001b[32m    137\u001b[39m     arr = cast(np.ndarray, arr)\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m     arr = \u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmaybe_convert_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m arr\n",
      "\u001b[36mFile \u001b[39m\u001b[32mlib.pyx:2476\u001b[39m, in \u001b[36mpandas._libs.lib.maybe_convert_objects\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: Buffer has wrong number of dimensions (expected 1, got 3)"
     ]
    }
   ],
   "source": [
    "# listar todos los archivos midi \n",
    "\n",
    "_path = \"dataset/music_artist/haydn\"\n",
    "\n",
    "\n",
    "data = []\n",
    "\n",
    "preprocessor = Preprocessor()\n",
    "\n",
    "\n",
    "\n",
    "for filename in os.listdir(_path):\n",
    "    file_path = os.path.join(_path, filename)\n",
    "\n",
    "    notes = preprocessor.load_midi_files(file_path)\n",
    "\n",
    "    if notes:\n",
    "        features = preprocessor.extract_features(notes)\n",
    "\n",
    "        # a√±adir nota de inicio\n",
    "        start_note = np.array([[\"START\", 0.0, 0.0, 0]], dtype=object)\n",
    "\n",
    "        # a√±adir nota de fin\n",
    "        end_note = np.array([[\"END\", 0.0, 0.0, 0]], dtype=object)\n",
    "\n",
    "        # Unir todo\n",
    "        song_sequence = np.vstack([start_note, features, end_note])\n",
    "\n",
    "        data.extend(song_sequence.tolist())\n",
    "\n",
    "    all_sequence = preprocessor.build_sequences(data, context_size=10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# df = preprocessor.get_notes_dataframe(data)\n",
    "\n",
    "# print(df)\n",
    "\n",
    "# print(preprocessor.get_notes_dataframe(all_features[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BORRAR ESTA CELDA\n",
    "\n",
    "preprocessor = Preprocessor()\n",
    "notes = preprocessor.load_midi_files('dataset/example.midi')\n",
    "data = preprocessor.extract_features(notes)\n",
    "\n",
    "print(\"notes:\", data)\n",
    "\n",
    "df = pd.DataFrame(data, columns=['pitch', 'step', 'duration', 'velocity'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conver to pandas for visualization\n",
    "\n",
    "# test with example.mid\n",
    "def convert_to_dataframe(data):\n",
    "    df = pd.DataFrame(data, columns=['pitch', 'step', 'duration', 'velocity'])\n",
    "    return df\n",
    "\n",
    "def plot_data(df):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(df['step'], df['duration'], c=df['pitch'], cmap='viridis', alpha=0.5)\n",
    "    plt.colorbar(label='Pitch')\n",
    "    plt.xlabel('Step')\n",
    "    plt.ylabel('Duration')\n",
    "    plt.title('MIDI Note Data')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pitch      step  duration  velocity\n",
      "0     67  0.335195  0.552632        49\n",
      "1     71  0.552632  0.078947        47\n",
      "2     69  0.078947  0.322580        47\n",
      "3     62  0.322580  0.312500        49\n",
      "4     64  0.312500  0.312500        45\n"
     ]
    }
   ],
   "source": [
    "_path = 'dataset/music_artist/haydn'\n",
    "\n",
    "# Extraer notas del archivo MIDI\n",
    "\n",
    "data = load_all_notes_from_folder(_path)\n",
    "\n",
    "len(data)\n",
    "\n",
    "# Convertir a DataFrame para visualizaci√≥n\n",
    "df = convert_to_dataframe(data)\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(df, context=10):\n",
    "    data = df[['pitch', 'step', 'duration', 'velocity']].values\n",
    "    sequences = []\n",
    "    targets = []\n",
    "    for i in range(len(data) - context):\n",
    "        seq = data[i:i+context]\n",
    "        target = data[i+context]\n",
    "        sequences.append(seq)\n",
    "        targets.append(target)\n",
    "    return np.array(sequences), np.array(targets)\n",
    "\n",
    "X, y = create_sequences(df, context=10)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Construcci√≥n del modelo\n",
    "\n",
    "\n",
    "Caracter√≠sticas de entrada \n",
    "\n",
    "- Pitch (altura de la nota): variable categ¬¥orica que representa la nota musical.\n",
    "- Step (tiempo): variable numerica que se debe calcular como el start de la nota actual menos el start de la nota anterior, y representa el espacio de tiempo que hay entre la   ota anterior y la nota actual.\n",
    "- Duration (duraci√≥n): variable num√©rica, se calcula como la diferencia entre el tiempo en el que termina la nota actual (end) menos el tiempo en el que inicio la nota (start), o que refleja la duracion en tiempo de la nota.\n",
    "- velocity (velocidad): variable num√©rica que representa la velocidad de la nota\n",
    "\n",
    "\n",
    "Para construir el modelo de generaci√≥n de m√∫sica, se utilizar√° una red neuronal recurrente (RNN) con capas LSTM. Las RNN son adecuadas para tareas de secuencias, como la generaci√≥n de m√∫sica, ya que pueden capturar dependencias a largo plazo en los datos.\n",
    "Se utilizar√° la biblioteca `torch` para construir el modelo. A continuaci√≥n se presenta un ejemplo de c√≥mo se puede definir una clase para el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoteDataset(Dataset):\n",
    "    def __init__(self, sequences: list, targets: list):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        sequennces: lista de notas que ser√°n usadas como entrada del modelo (contexto de notas anteriores)\n",
    "        targets: lista de notas que ser√°n usadas como salida del modelo (notas a predecir)\n",
    "\n",
    "        x = [Nota_{t-c}, ..., Nota_{t-1}]\n",
    "        y = [Nota_{t}]\n",
    "        \"\"\"\n",
    "        self.sequences = sequences\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"N√∫mero de secuencias en el dataset.\"\"\"\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Obtiene un elemento del dataset dado un √≠ndice.\n",
    "\n",
    "        convierte la secuencia y el target a tensores de PyTorch.\n",
    "        \"\"\"\n",
    "        return torch.tensor(self.sequences[idx], dtype=torch.float32), \\\n",
    "                torch.tensor(self.targets[idx], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicLSTM(nn.Module):\n",
    "    def __init__(self, input_size: int, hidden_size: int, num_layers: int):\n",
    "        \"\"\"\n",
    "        Initialize the LSTM model.\n",
    "\n",
    "        Args:\n",
    "            input_size (int): Size of the input features.\n",
    "            hidden_size (int): Number of features in the hidden state.\n",
    "            num_layers (int): Number of recurrent layers.\n",
    "\n",
    "        \n",
    "        \"\"\"\n",
    "        super(MusicLSTM, self).__init__()\n",
    "        \n",
    "        # Definimos la arquitectura de la red LSTM\n",
    "\n",
    "        # input_size: n√∫mero de caracter√≠sticas de entrada (4 en este caso: pitch, step, duration, velocity)\n",
    "        # hidden_size: n√∫mero de caracter√≠sticas en el estado oculto\n",
    "        # num_layers: n√∫mero de capas LSTM apiladas\n",
    "        # batch_first=True: la entrada y salida de la LSTM ser√°n de tama√±o (batch, seq, feature)\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "\n",
    "\n",
    "        # Definimos las capas de salida para cada una de las caracter√≠sticas a predecir\n",
    "        # pitch, step, duration y velocity\n",
    "        # Cada una de estas capas toma como entrada el estado oculto final de la LSTM y produce una salida \n",
    "        self.fc_pitch = nn.Linear(hidden_size, 128)\n",
    "        self.fc_step = nn.Linear(hidden_size, 1)\n",
    "        self.fc_duration = nn.Linear(hidden_size, 1)\n",
    "        self.fc_velocity = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass de la red LSTM.\n",
    "        Args:\n",
    "            x: tensor de entrada con forma (batch_size, seq_length, input_size)\n",
    "        Returns:\n",
    "            pitch: tensor de salida para la predicci√≥n de pitch\n",
    "            step: tensor de salida para la predicci√≥n de step\n",
    "            duration: tensor de salida para la predicci√≥n de duration\n",
    "            velocity: tensor de salida para la predicci√≥n de velocity\n",
    "        \"\"\"\n",
    "        out,_ = self.lstm(x)\n",
    "        out = out[:, -1, :] # tomamos solo el √∫ltimo paso\n",
    "        pitch = self.fc_pitch(out)\n",
    "        step = self.fc_step(out)\n",
    "        duration = self.fc_duration(out)\n",
    "        velocity = self.fc_velocity(out)\n",
    "        return pitch, step, duration, velocity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train_model(model: nn.Module, dataloader: DataLoader, epochs: int, criterion_pitch: nn.Module, criterion_reg: nn.Module, optimizer: torch.optim.Optimizer):\n",
    "    \"\"\"\n",
    "    Train the LSTM model.\n",
    "    Args:\n",
    "        model (nn.Module): The LSTM model to train.\n",
    "        dataloader (DataLoader): DataLoader for the training data.\n",
    "        epochs (int): Number of epochs to train.\n",
    "        criterion_pitch (nn.Module): Loss function for pitch.\n",
    "        criterion_reg (nn.Module): Loss function for regression targets.\n",
    "        optimizer (torch.optim.Optimizer): Optimizer for training.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        loop = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=False)\n",
    "        for batch_x, batch_y in loop:\n",
    "\n",
    "            # x_batch: (batch_size, seq_length, input_size)\n",
    "            # y_batch: (batch_size, 4) (pitch, step, duration, velocity)\n",
    "\n",
    "            # separar cada una de las caracter√≠sticas de salida\n",
    "            pitch_true = batch_y[:, 0].long()\n",
    "            step_true = batch_y[:, 1].unsqueeze(1)\n",
    "            duration_true = batch_y[:, 2].unsqueeze(1)\n",
    "            velocity_true = batch_y[:, 3].unsqueeze(1)\n",
    "\n",
    "            # limitar el gradiente\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward pass\n",
    "            pitch_pred, step_pred, duration_pred, velocity_pred = model(batch_x)\n",
    "\n",
    "\n",
    "            # calcular la p√©rdida para cada una de las caracter√≠sticas\n",
    "            loss_pitch = criterion_pitch(pitch_pred, pitch_true)\n",
    "            loss_step = criterion_reg(step_pred, step_true)\n",
    "            loss_duration = criterion_reg(duration_pred, duration_true)\n",
    "            loss_velocity = criterion_reg(velocity_pred, velocity_true)\n",
    "\n",
    "            loss = loss_pitch + loss_step + loss_duration + loss_velocity\n",
    "\n",
    "            # backward pass y optimizaci√≥n\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Agregar la p√©rdida total\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        # √≠mprimir la p√©rdida total por cada epoch \n",
    "        print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 363801.3507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 93435.4376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 36339.0696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 29205.0231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 28836.7888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 28795.5217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 28826.2194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 28803.3319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 28839.0810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 28799.1056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss: 28783.5815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Loss: 28814.9354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Loss: 28808.3467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Loss: 28789.8442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Loss: 28814.9492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Loss: 28807.8063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Loss: 28789.5747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Loss: 28816.8825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Loss: 28822.9832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Loss: 28817.7173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21, Loss: 28818.3540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, Loss: 28796.4607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23, Loss: 28840.4004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, Loss: 28814.7531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25, Loss: 28838.0105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26, Loss: 28817.1716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27, Loss: 28856.1811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28, Loss: 28877.3993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29, Loss: 28824.2206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30, Loss: 28815.7346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31, Loss: 28830.4145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32, Loss: 28857.4754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33, Loss: 28797.0036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34, Loss: 28792.2369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35, Loss: 28804.5841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36, Loss: 28811.5657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37, Loss: 28798.5599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38, Loss: 28844.3578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39, Loss: 28819.5135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40, Loss: 28816.1220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41, Loss: 28828.7907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42, Loss: 28807.7581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43, Loss: 28807.1381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44, Loss: 28823.8493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45, Loss: 28831.9673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46, Loss: 28877.6942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47, Loss: 28855.5124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48, Loss: 28836.4301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49, Loss: 28824.7358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Loss: 28812.8339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51, Loss: 28854.3705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52, Loss: 28841.5739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53, Loss: 28844.2508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54, Loss: 28827.4093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55, Loss: 28841.4819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56, Loss: 28823.6595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57, Loss: 28855.0865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58, Loss: 28806.6538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59, Loss: 28819.4953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60, Loss: 28828.2621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62, Loss: 28845.0393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63, Loss: 28814.4679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64, Loss: 28837.2839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65, Loss: 28815.3133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66, Loss: 28821.3117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67, Loss: 28818.9945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68, Loss: 28815.6021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69, Loss: 28812.1363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70, Loss: 28814.2400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71, Loss: 22022.5546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72, Loss: 12533.3375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73, Loss: 10805.8151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74, Loss: 10124.1195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75, Loss: 9629.9769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76, Loss: 9120.7027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77, Loss: 8890.5609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78, Loss: 8497.2175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79, Loss: 8344.1453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80, Loss: 8044.6277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81, Loss: 7781.5581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82, Loss: 7880.2222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83, Loss: 7463.7991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84, Loss: 7399.0810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85, Loss: 7071.4564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86, Loss: 6914.2627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87, Loss: 6624.5520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88, Loss: 6511.3430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89, Loss: 6362.9029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90, Loss: 6105.7738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91, Loss: 5856.2099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92, Loss: 5552.4426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93, Loss: 5335.1274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94, Loss: 5226.1594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95, Loss: 4903.7022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96, Loss: 4764.7320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97, Loss: 4632.0488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98, Loss: 4465.4489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99, Loss: 4022.3436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, Loss: 4107.3184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Hiperpar√°metros\n",
    "input_size = 4           # pitch, step, duration, velocity\n",
    "hidden_size = 128\n",
    "num_layers = 8\n",
    "batch_size = 64\n",
    "epochs = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Dataset y DataLoader\n",
    "train_dataset = NoteDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Inicializar modelo\n",
    "model = MusicLSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers)\n",
    "\n",
    "# Funciones de p√©rdida\n",
    "criterion_pitch = nn.CrossEntropyLoss()\n",
    "criterion_reg = nn.MSELoss()\n",
    "\n",
    "# Optimizador\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Llamar al entrenamiento\n",
    "train_model(\n",
    "    model=model,\n",
    "    dataloader=train_loader,\n",
    "    criterion_pitch=criterion_pitch,\n",
    "    criterion_reg=criterion_reg,\n",
    "    optimizer=optimizer,\n",
    "    epochs=epochs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sequence(model, seed_sequence, length, context=10, device='cpu'):\n",
    "    model.eval()\n",
    "    generated = []\n",
    "    current_seq = seed_sequence.copy()\n",
    "\n",
    "    for _ in range(length):\n",
    "        # Asegura que solo se tomen las √∫ltimas `context` notas\n",
    "        input_seq = current_seq[-context:]\n",
    "        input_tensor = torch.tensor(input_seq, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pitch_logits, step, duration, velocity = model(input_tensor)\n",
    "\n",
    "        # Predecir pitch con argmax\n",
    "        pitch = torch.argmax(pitch_logits, dim=1).item()\n",
    "\n",
    "        # Extraer valores escalares de salida\n",
    "        step = step.item()\n",
    "        duration = duration.item()\n",
    "        velocity = velocity.item()\n",
    "\n",
    "        # Guardar la nota generada\n",
    "        generated.append([pitch, step, duration, velocity])\n",
    "\n",
    "        # Agregar la nueva nota a la secuencia\n",
    "        current_seq.append([pitch, step, duration, velocity])\n",
    "\n",
    "    return generated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_midi(notes, output_path, instrument_name=\"Acoustic Grand Piano\"):\n",
    "    pm = pretty_midi.PrettyMIDI()\n",
    "    instrument = pretty_midi.Instrument(program=pretty_midi.instrument_name_to_program(instrument_name))\n",
    "    start = 0\n",
    "    for note in notes:\n",
    "        pitch, step, duration, velocity = note\n",
    "        start += step\n",
    "        end = start + duration\n",
    "        note_obj = pretty_midi.Note(velocity=int(velocity), pitch=int(pitch), start=start, end=end)\n",
    "        instrument.notes.append(note_obj)\n",
    "    pm.instruments.append(instrument)\n",
    "    pm.write(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Par√°metros\n",
    "context = 10\n",
    "num_notes = 200\n",
    "device = 'cpu'  # o 'cuda' si est√°s usando GPU\n",
    "\n",
    "# Semilla: las primeras 10 notas del set de entrenamiento\n",
    "seed_sequence = X_train[0].tolist()\n",
    "\n",
    "# Generar notas\n",
    "generated_notes = generate_sequence(\n",
    "    model=model,\n",
    "    seed_sequence=seed_sequence,\n",
    "    length=num_notes,\n",
    "    context=context,\n",
    "    device=device\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_midi(\n",
    "    notes=generated_notes,\n",
    "    output_path='generated_music.mid',\n",
    "    instrument_name=\"Acoustic Grand Piano\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Una sin memoria",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
